<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Possibility of heteroskedasticity is a good reason not to dichotomize a continuous variable for use as outcome in logistic regression. | James Uanhoro</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/post/">Blog posts</a></li>
      
      <li><a href="/projects/">Programming projects</a></li>
      
      <li><a href="/tags/">Tags</a></li>
      
      <li><a href="/index.xml">Subscribe</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Possibility of heteroskedasticity is a good reason not to dichotomize a continuous variable for use as outcome in logistic regression.</span></h1>
<h2 class="author">James Uanhoro</h2>
<h2 class="date">2018/10/20</h2>
</div>

<main>
<p>Continuing on whether it&rsquo;s a good idea to dichotomize continuous variables prior to analysis for substantive reasons, I think I settle on the side of bad idea. The major reason is potential heteroskedasticity of the error term in the linear regression model for the original continuous variable.</p>
<p>This is an interesting issue, but one that I do not want to devote time to write about. So I decided to write a brief methods note. The goal is that the document is easy to read, simple and at least causes any reader to rethink dichotomization if they do it normally. However, none of it is new.</p>
<embed src="/pdf/dicho_het_log/dicho_het_log.pdf" width="800px" height="700px" />
<p>Links:</p>
<ul>
<li><a href="/pdf/dicho_het_log/dicho_het_log.pdf">PDF</a></li>
<li><a href="/pdf/dicho_het_log/dicho_het_log.Rmd">Rmarkdown document which contains source here</a> (with <a href="/pdf/dicho_het_log/r-references.bib">references</a>).</li>
<li>I used <a href="https://github.com/crsh/papaja">papaja</a> to compile the document.</li>
</ul>
<p>N.B.: I don&rsquo;t mention it in the methodological note, but the reason methods like generalized additive models and kernel regularized least squares with logistic loss might work is heteroskedasticity in the continuous variable manifests as a different mean function than the inverse logit function. So methods that relax the linearity assumptions of regression (linear/logistic) can do a good job estimating the true relations in the data.</p>

</main>

<script>talkyardServerUrl='https:\/\/comments-for-www-jamesuanhoro-com.talkyard.net';</script>
<script async defer src="https://c1.ty-cdn.net/-/talkyard-comments.min.js"></script>

<div class="talkyard-comments" data-discussion-id="" style="margin-top: 45px;">
<noscript>Please enable Javascript to view comments.</noscript>
<p style="margin-top: 25px; opacity: 0.9">Comments powered by
<a href="https://www.talkyard.io">Talkyard</a>.</p>
</div>

  <footer>
  <script defer src="//yihui.org/js/math-code.js"></script>
<script defer src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script defer src="//yihui.org/js/center-img.js"></script>

  
  <hr/>
  James Uanhoro | <a href="https://keybase.io/jamesuanhoro">Verified digital identities</a> | Powered by: <a href="https://www.netlify.com/">Netlify</a>, <a href="https://gohugo.io/">Hugo</a>, <a href="https://themes.gohugo.io/hugo-xmin/">Hugo XMin</a>
  
  </footer>
  </body>
</html>

